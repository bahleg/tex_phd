
\chapter*{Заключение}
Основные результаты диссертационной работы заключаются в следующем.

В главе 1 введены основные понятия, поставлены задачи выбора модели глубокого обучения и проанализированы
методы оптимизации параметров модели, методы оптимизации гиперпараметров, методы представления моделей глубокого обучения в графовом виде, методы оптимизации структурных параметров и метапараметров модели. Последние включают в себя как эвристические методы, так и методы, основанные на байесовском выводе и вероятностных предположениях о распределении параметров, гиперпараметров и метапараметров модели.

В главе 2 были предложены критерии оптимальной и субоптимальной сложности моделей глубокого обучения. Предложен алгоритм выбора субоптимальной модели, основанный на получении вариационной нижней оценки  правдоподобия модели. Был предложен метод получения оценки, основанный на стохастическом градиентном спуске, позволяющий проводить выбор модели и оптимизацию модели единообразно. Исследованы свойства стохастического градиентного спуска, а также оценок правдоподобия, полученных с его использованием. 
Работа представленного алгоритма проиллюстрирована рядом выборок. 
Вычислительный эксперимент продемонстрировал значимое влияние априорного распределения на апостериорное распределение параметров модели. 

В главе 3 были проанализированы градиентные методы оптимизации гиперпараметров. Предложено обобщение существующих методов на функции потерь и валидации общего вида.
Было проведено сравнение двух критериев выбора модели: на основе кросс-валидации и на основе вариационной оценки правдоподобия модели.
Экспреименты показали, что градиентные методы оптимизации гиперпараметров являются эффективными в случае, когда число гиперпараметров велико. Также эксперименты показали, что те модели, гиперпараметры и параметры которых были оптимизированы с использованием вариационной оценки правдоподобия модели, имеют меньшую точность классификации, чем те модели, чьи гиперпараметры и параметры были оптимизированы с использованием метода кросс-валидации. В то же время, первые модели оказались более робастными при доабвлении шума в выборку. Модели, чья оптимизация проводилась с использованием вариационной оценки правдоподобия, оказались значительно лучшими на синтетической выборке, когда число объетов в обучающей выборке мало по сравнению с числом параметров. Поэтому вариационная оценка правдоподобия более предпочтительна, когда вероятность переобучения моделей велика или когда проведение кросс-валидации вычислительно затратно.

В главе 4 был предложен обобщенный метод выбора структуры модели субоптимальной сложности. Формализовано понятие параметрической сложности для вероятностных моделей. Сформулированы требования к вариационным распределениям, введенным на структуре модели. Показано, что предложенный метод выбора структуры модели обощает такие методы выбора модели как оптимизация согласно критерию максимального правдоподобия, оптимизация вариационной оценки обоснованности модели, снижение и увеличение сложности модели, а также полный перебор.

В главе 5 проведен анализ свойств предложенных методов. Описан реализованный программный комплекс, позволяющий осуществлять выбор моделей глубокого обучения. Проведено сравнение предложенных алгоритмов с известными решениями. Предложенные алгоритмы показали более высокие результаты. 

